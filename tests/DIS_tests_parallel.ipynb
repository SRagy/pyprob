{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprob\n",
    "import numpy as np\n",
    "import ot\n",
    "import torch\n",
    "import cProfile\n",
    "\n",
    "from pyprob.dis import ModelDIS\n",
    "from showerSim import invMass_ginkgo\n",
    "from pyprob.nn.dataset import OnlineDataset\n",
    "from pyprob.util import InferenceEngine\n",
    "from pyprob.util import to_tensor\n",
    "from pyprob import Model\n",
    "import math\n",
    "from pyprob.distributions import Normal\n",
    "from pyprob.distributions.delta import Delta\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as mpl_cm\n",
    "plt.ion()\n",
    "\n",
    "import sklearn as skl\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from geomloss import SamplesLoss\n",
    "sinkhorn = SamplesLoss(loss=\"sinkhorn\", p=1, blur=.05)\n",
    "def sinkhorn_t(x,y):\n",
    "    x = to_tensor(x)\n",
    "    y = torch.stack(y)\n",
    "    return sinkhorn(x,y)\n",
    "\n",
    "def ot_dist(x,y):\n",
    "    # x = torch.tensor(x)\n",
    "    # y = torch.stack(y)\n",
    "    x = np.array(x)\n",
    "    y = np.array(torch.stack(y))\n",
    "    a = ot.unif(len(x))\n",
    "    b = ot.unif(len(y))\n",
    "    Mat = ot.dist(x, y, metric='euclidean')\n",
    "    #Mat1 /= Mat1.max()\n",
    "    distance = torch.tensor(ot.emd2(a,b,Mat))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Quadro RTX 6000'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = \"cuda\"\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprob.util import set_device\n",
    "set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obs_leaves = to_tensor([[44.57652381, 26.16169856, 25.3945314 , 25.64598258],\n",
    "                           [18.2146321 , 10.70465096, 10.43553391, 10.40449709],\n",
    "                           [ 6.47106713,  4.0435395,  3.65545951,  3.48697568],\n",
    "                           [ 8.43764314,  5.51040615,  4.60990593,  4.42270416],\n",
    "                           [26.61664145, 16.55894826, 14.3357362 , 15.12215264],\n",
    "                           [ 8.62925002,  3.37121204,  5.19699   ,  6.00480461],\n",
    "                           [ 1.64291837,  0.74506775,  1.01003622,  1.05626017],\n",
    "                           [ 0.75525072,  0.3051808 ,  0.45721085,  0.51760643],\n",
    "                           [39.5749915 , 18.39638928, 24.24717939, 25.29349408],\n",
    "                           [ 4.18355659,  2.11145474,  2.82071304,  2.25221316],\n",
    "                           [ 0.82932922,  0.29842766,  0.5799056 ,  0.509021  ],\n",
    "                           [ 3.00825023,  1.36339397,  1.99203677,  1.79428211],\n",
    "                           [ 7.20024308,  4.03280868,  3.82379277,  4.57441754],\n",
    "                           [ 2.09953618,  1.28473579,  1.03554351,  1.29769683],\n",
    "                           [12.21401828,  6.76059035,  6.94920042,  7.42823701],\n",
    "                           [ 6.91438054,  3.68417135,  3.83782514,  4.41656731],\n",
    "                           [ 1.97218904,  1.01632927,  1.08008339,  1.27454585],\n",
    "                           [ 8.58164301,  5.06157833,  4.79691164,  4.99553141],\n",
    "                           [ 5.97809522,  3.26557958,  3.4253764 ,  3.64894791],\n",
    "                           [ 5.22842301,  2.94437891,  3.10292633,  3.00551074],\n",
    "                           [15.40023764,  9.10884407,  8.93836964,  8.61970667],\n",
    "                           [ 1.96101346,  1.24996337,  1.06923988,  1.06743143],\n",
    "                           [19.81054106, 11.90268453, 11.60989346, 10.76953856],\n",
    "                           [18.79470876, 11.429855  , 10.8377334 , 10.25112761],\n",
    "                           [25.74331932, 15.63430056, 14.83860792, 14.07189108],\n",
    "                           [ 9.98357576,  6.10090721,  5.68664128,  5.48748692],\n",
    "                           [12.34604239,  7.78770185,  6.76075998,  6.78498685],\n",
    "                           [21.24998531, 12.95180254, 11.9511704 , 11.87319933],\n",
    "                           [ 7.80693733,  4.83117128,  4.27443559,  4.39602348],\n",
    "                           [16.28983576,  9.66683929,  9.24891886,  9.28970032],\n",
    "                           [ 2.50706736,  1.53153206,  1.36060018,  1.43002765],\n",
    "                           [ 3.73938645,  2.06006639,  2.31013974,  2.09378969],\n",
    "                           [20.2174725 , 11.88622367, 12.05106468, 11.05325362],\n",
    "                           [ 9.48660008,  5.53665456,  5.54171966,  5.34966654],\n",
    "                           [ 2.65812987,  1.64102742,  1.67392209,  1.25083707]])\n",
    "\n",
    "\n",
    "QCD_mass = to_tensor(30.)\n",
    "#rate=to_tensor([QCD_rate,QCD_rate]) #Entries: [root node, every other node] decaying rates. Choose same values for a QCD jet\n",
    "jetdir = to_tensor([1.,1.,1.])\n",
    "jetP = to_tensor(400.)\n",
    "jetvec = jetP * jetdir / torch.linalg.norm(jetdir) ## Jetvec is 3-momentum. JetP is relativistic p.\n",
    "\n",
    "\n",
    "# Actual parameters\n",
    "pt_min = to_tensor(0.3**2)\n",
    "M2start = to_tensor(QCD_mass**2)\n",
    "jetM = torch.sqrt(M2start) ## Mass of initial jet\n",
    "jet4vec = torch.cat((torch.sqrt(jetP**2 + jetM**2).reshape(-1), jetvec))\n",
    "minLeaves = 1\n",
    "maxLeaves = 10000 # unachievable, to prevent rejections\n",
    "maxNTry = 100\n",
    "\n",
    "\n",
    "\n",
    "class SimulatorModelDIS(invMass_ginkgo.SimulatorModel, ModelDIS):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def dummy_bernoulli(self, jet):\n",
    "        return True\n",
    "\n",
    "    def forward(self, inputs=None):\n",
    "        assert inputs is None # Modify code if this ever not met?\n",
    "        # Sample parameter of interest from Unif(0,10) prior\n",
    "        root_rate = pyprob.sample(pyprob.distributions.Uniform(0.01, 10.),\n",
    "                                  name=\"decay_rate_parameter\")\n",
    "        decay_rate = pyprob.sample(pyprob.distributions.Uniform(0.01, 10.),\n",
    "                                   name=\"decay_rate_parameter\")\n",
    "        # Simulator code needs two decay rates for (1) root note (2) all others\n",
    "        # For now both are set to the same value\n",
    "        inputs = [root_rate, decay_rate]\n",
    "        jet = super().forward(inputs)\n",
    "        delta_val = self.dummy_bernoulli(jet)\n",
    "        bool_func_dist = pyprob.distributions.Bernoulli(delta_val)\n",
    "        pyprob.observe(bool_func_dist, name = \"dummy\")\n",
    "        return jet\n",
    "\n",
    "# Make instance of the simulator\n",
    "simulatorginkgo = SimulatorModelDIS(jet_p=jet4vec,  # parent particle 4-vector\n",
    "                                    pt_cut=float(pt_min),  # minimum pT for resulting jet\n",
    "                                    Delta_0= M2start,  # parent particle mass squared -> needs tensor\n",
    "                                    M_hard=jetM,  # parent particle mass\n",
    "                                    minLeaves=1,  # minimum number of jet constituents\n",
    "                                    maxLeaves=10000,  # maximum number of jet constituents (a large value to stop expensive simulator runs)\n",
    "                                    suppress_output=True,\n",
    "                                    obs_leaves=obs_leaves,\n",
    "                                    dist_fun=sinkhorn_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new inference network...\n",
      "Time spent  | Time remain.| Progress             | Trace   | ESS   | Traces/sec\n",
      "0d:00:00:13 | 0d:00:00:00 | #################### | 100/100 | 100.00 | 7.34       \r\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_57048/2876795688.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0msimulatorginkgo\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterations\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimportance_sample_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/dispyprob/pyprob/pyprob/dis.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, iterations, importance_sample_size, ess_target, batch_size, nbatches, **kwargs)\u001B[0m\n\u001B[1;32m    134\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterations\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m             \u001B[0;31m# TO DO: suppress messages about OfflineDataset creation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 136\u001B[0;31m             self.learn_inference_network(\n\u001B[0m\u001B[1;32m    137\u001B[0m                 \u001B[0mnum_traces\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnbatches\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    138\u001B[0m                 \u001B[0mimportance_sample_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mimportance_sample_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dispyprob/pyprob/pyprob/model.py\u001B[0m in \u001B[0;36mlearn_inference_network\u001B[0;34m(self, num_traces, num_traces_end, inference_engine, importance_sample_size, ess_target, inference_network, prior_inflation, dataset_dir, dataset_valid_dir, observe_embeddings, batch_size, valid_size, valid_every, optimizer_type, learning_rate_init, learning_rate_end, learning_rate_scheduler_type, momentum, weight_decay, save_file_name_prefix, save_every_sec, pre_generate_layers, distributed_backend, distributed_params_sync_every_iter, distributed_num_buckets, dataloader_offline_num_workers, stop_with_bad_loss, log_file_name, lstm_dim, lstm_depth, proposal_mixture_components)\u001B[0m\n\u001B[1;32m    224\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_inference_network\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_device\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 226\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_inference_network\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_traces\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_traces\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset_valid\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdataset_valid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_traces_end\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_traces_end\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_every\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalid_every\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moptimizer_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate_init\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlearning_rate_init\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate_end\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlearning_rate_end\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate_scheduler_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlearning_rate_scheduler_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmomentum\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmomentum\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight_decay\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mweight_decay\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msave_file_name_prefix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msave_file_name_prefix\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msave_every_sec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msave_every_sec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdistributed_backend\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdistributed_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdistributed_params_sync_every_iter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdistributed_params_sync_every_iter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdistributed_num_buckets\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdistributed_num_buckets\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataloader_offline_num_workers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdataloader_offline_num_workers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_with_bad_loss\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstop_with_bad_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlog_file_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlog_file_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    227\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    228\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0msave_inference_network\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dispyprob/pyprob/pyprob/nn/inference_network.py\u001B[0m in \u001B[0;36moptimize\u001B[0;34m(self, num_traces, dataset, dataset_valid, num_traces_end, batch_size, valid_every, optimizer_type, learning_rate_init, learning_rate_end, learning_rate_scheduler_type, momentum, weight_decay, save_file_name_prefix, save_every_sec, distributed_backend, distributed_params_sync_every_iter, distributed_num_buckets, dataloader_offline_num_workers, stop_with_bad_loss, log_file_name)\u001B[0m\n\u001B[1;32m    381\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0moptimize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_traces\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset_valid\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_traces_end\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1e9\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m64\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_every\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mOptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mADAM\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate_init\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.0001\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate_end\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1e-6\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate_scheduler_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mLearningRateScheduler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNONE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmomentum\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.9\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight_decay\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1e-5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msave_file_name_prefix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msave_every_sec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m600\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdistributed_backend\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdistributed_params_sync_every_iter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10000\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdistributed_num_buckets\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataloader_offline_num_workers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_with_bad_loss\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlog_file_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    382\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_layers_initialized\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 383\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_init_layers_observe_embedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_observe_embeddings\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexample_trace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    384\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_init_layers\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    385\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_layers_initialized\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dispyprob/pyprob/pyprob/nn/inference_network.py\u001B[0m in \u001B[0;36m_init_layers_observe_embedding\u001B[0;34m(self, observe_embeddings, example_trace)\u001B[0m\n\u001B[1;32m     94\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Observable {}: reshape to {}.'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 96\u001B[0;31m                 \u001B[0minput_shape\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvariable\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     97\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Observable {}: reshape not specified, using shape {}.'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;34m'dim'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "simulatorginkgo.train(iterations = 1, importance_sample_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}